{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Search_engine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVEP4rbo1U9"
      },
      "source": [
        "#connection with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV7VPCVE3ctZ"
      },
      "source": [
        "#set seed and import needed libraries\n",
        "SEED = 1234\n",
        "! pip install pyprind\n",
        "import os\n",
        "import json\n",
        "import nltk\n",
        "import torch\n",
        "import random\n",
        "import pyprind\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data\n",
        "torch.backends.cudnn.deterministic = True\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "torch.cuda.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMWO5QJY3xrr"
      },
      "source": [
        "#use cuda if it's available\n",
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgcYKWqv30rM"
      },
      "source": [
        "#load file pt for images\n",
        "import tarfile\n",
        "t = tarfile.open('/content/drive/MyDrive/coco_object/coco_object_features.tar.gz', 'r')\n",
        "t.extractall(\"/content/drive/MyDrive/pt/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDUdMWKC33gT"
      },
      "source": [
        "#count number of pt's file\n",
        "path, dirs, files = next(os.walk(\"/content/drive/MyDrive/coco_object_features/features\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSpU7CvaZEEb"
      },
      "source": [
        "#create a vocab using glove, than add a vector for absent values\n",
        "vocab = torchtext.vocab.Vectors(\"/content/drive/MyDrive/embedding/glove.6B.300d.txt\")\n",
        "vector_400000 = torch.zeros(300)\n",
        "vector_400000.view(1,300).shape\n",
        "vocab.vectors = torch.cat((vocab.vectors, vector_400000.view(1,300)), dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IEVexjM35Lh"
      },
      "source": [
        "#load dataset\n",
        "validation1 = pd.read_json(\"/content/drive/MyDrive/Text_Image_Datasets/Doc1.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQNbOVHwsdmB"
      },
      "source": [
        "#create a dataframe which has for every row only one caption_id and one iamge_id.\n",
        "#the same caption_id will be repated for the first n rows. Where n is the number of images in a pool.\n",
        "df = pd.DataFrame(columns = [\"cap_id\", \"img_id\"])\n",
        "for i in range(len(validation1)):\n",
        "  for y in range(250):\n",
        "    caption_id = validation1.id[i]\n",
        "    image_id = validation1.images_id[i][y]\n",
        "    row = {\"cap_id\":caption_id, \"img_id\":image_id}\n",
        "    df = df.append(row, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klnjom2XuBgw"
      },
      "source": [
        "#Create a dict for captions.\n",
        "#The keys are the captions_ids and the values are a list of the words indexes (from the vocab)\n",
        "vocabolario1 = {}              \n",
        "for i in range(len(validation1)):\n",
        "  id = validation1['id'][i]\n",
        "  caption = validation1['caption'][i].lower()\n",
        "  caption = nltk.word_tokenize(caption)\n",
        "  word_idx=[]\n",
        "  tensor_idx=[]\n",
        "  for word in caption:          \n",
        "    try:\n",
        "      index = vocab.stoi[word]\n",
        "      word_idx.append(index)\n",
        "    except KeyError:\n",
        "      word_idx.append(400000) \n",
        "  while len(word_idx) <13:\n",
        "    word_idx.append(400000)\n",
        "  word_idx = word_idx[:12]\n",
        "  for idx in word_idx:\n",
        "    tensor_idx.append(np.array(vocab.vectors[idx]))\n",
        "  vocabolario1[id]=torch.tensor(word_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrm3Xc25wcTI"
      },
      "source": [
        "#Create dict for images\n",
        "#The keys are the images_ids, the values are dictionaries with keys:\"classes\",\"features\" \n",
        "#and values are indexes of classes(using vocab) and features tensors.\n",
        "images_id = set(df['img_id'])\n",
        "vocabolario2 = {}\n",
        "for image_id in images_id:\n",
        "  file_pt = torch.load(\"/content/drive/MyDrive/coco_object_features/features/\"+'0' * (12-len(str(image_id))) + str(image_id) + '.pt',map_location=\"cuda:0\")\n",
        "  \n",
        "  classes_list=[]\n",
        "  for tag in file_pt['classes']:\n",
        "    try:\n",
        "      tag = tag.decode(\"utf-8\")\n",
        "      tag = tag.lower()\n",
        "      index = vocab.stoi[tag]\n",
        "\n",
        "      classes_list.append(np.array([index]))\n",
        "    except KeyError:\n",
        "      classes_list.append(np.array([400000]))\n",
        "    \n",
        "  file_pt['classes'] = torch.tensor(classes_list)\n",
        "  file_pt[\"features\"] = torch.tensor(file_pt[\"features\"])\n",
        "\n",
        "  vocabolario2[image_id] = file_pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCJLqqDS09yw"
      },
      "source": [
        "#Create Dataset class\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self,tabella):\n",
        "        self.samples = tabella\n",
        "    def __len__(self):\n",
        "      return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "      caption_id= self.samples.cap_id.iloc[idx]\n",
        "      image_id = self.samples.img_id.iloc[idx]\n",
        "\n",
        "      return torch.tensor(caption_id), torch.tensor(image_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBMW4PzXwq6N"
      },
      "source": [
        "#Start Dataloader\n",
        "dataset = Dataset(df)\n",
        "dataloader = DataLoader(dataset, batch_size=250, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubyquwkjgGdY"
      },
      "source": [
        "#define the class for the neural network\n",
        "class CRM(nn.Module): #cross retrieval match\n",
        "  def __init__(self, vocab_dim, embedding_language_dim, embedding_classes_dim, embedding_features_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings_language = nn.Embedding(vocab_dim, embedding_language_dim) \n",
        "        self.embeddings_language.load_state_dict({'weight': (vocab.vectors)})\n",
        "        self.rnn_language = nn.RNN(embedding_language_dim, hidden_dim, batch_first = True)\n",
        "\n",
        "        embedding_img_dim = embedding_classes_dim + embedding_features_dim\n",
        "        self.embeddings_visual = nn.Embedding(vocab_dim, embedding_classes_dim)\n",
        "        self.embeddings_visual.load_state_dict({'weight': (vocab.vectors)})\n",
        "        self.rnn_visual = nn.RNN(embedding_img_dim, hidden_dim, batch_first = True)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim + hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, caption_idx, embedding_features, classes_idx):\n",
        "\n",
        "          embedding_text = self.embeddings_language(caption_idx)\n",
        "          _,hidden_language = self.rnn_language(embedding_text)\n",
        "\n",
        "          embedding_classes = self.embeddings_visual(classes_idx)\n",
        "          embedding_image = torch.cat((embedding_features, embedding_classes), dim=-1)\n",
        "          _, hidden_visual = self.rnn_visual(embedding_image)\n",
        "          \n",
        "\n",
        "          hidden = torch.cat((hidden_language, hidden_visual), dim = -1)\n",
        "          \n",
        "          #import pdb; pdb.set_trace()\n",
        "\n",
        "\n",
        "          out = self.fc(hidden)\n",
        "          out = self.dropout(out)\n",
        "          #out = m(out)\n",
        "\n",
        "\n",
        "          return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0SMr7KU4qlG"
      },
      "source": [
        "#load classifer\n",
        "model_name=\"model_50_lesspadding.pt\" \n",
        "model = torch.load(\"/content/drive/MyDrive/models/\"+model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-dmVHKwpBln"
      },
      "source": [
        "#set RNN features\n",
        "VOCAB_DIM = len(vocab.vectors)\n",
        "EMBEDDING_CLASSES_DIM = 300\n",
        "EMBEDDING_FEATURES_DIM = 2048\n",
        "EMBEDDING_LANGUAGE_DIM = 300\n",
        "HIDDEN_DIM = 450\n",
        "OUTPUT_DIM = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZBcM4oL66Nl"
      },
      "source": [
        "#set weights and criterion\n",
        "class_weights = torch.tensor([1.0, 1.0]).cuda()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8fTWgyb6WRG"
      },
      "source": [
        "#Creating a function that uses batch results to covert ids into thier value using the dictionaries upon created\n",
        "def multi_dict(ids_list, dictionary_to_use,work_on_images=True):\n",
        "  features_for_CRM= []\n",
        "  classes_for_CRM= []\n",
        "  captions_for_CRM= []\n",
        "  if work_on_images == True:\n",
        "    for simple_id in ids_list:\n",
        "      features_for_CRM.append(dictionary_to_use[simple_id.item()]['features'])\n",
        "      classes_for_CRM.append(dictionary_to_use[simple_id.item()]['classes'])\n",
        "    return torch.stack(features_for_CRM).to(device), torch.stack(classes_for_CRM).to(device)\n",
        "  if work_on_images == False:\n",
        "    for simple_id in ids_list:\n",
        "      captions_for_CRM.append(dictionary_to_use[simple_id.item()])\n",
        "    return torch.stack(captions_for_CRM).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9kMosDLBZ-Z"
      },
      "source": [
        "#function that calculates the position of the correct image after ordering by score\n",
        "def ranking_tracker(prediction,batch):\n",
        "  y_true = int(batch[1][0]) #verificare\n",
        "  df = pd.DataFrame(columns = [\"id_image\", \"scores\"])\n",
        "  for i in range(250):\n",
        "    row = {\"id_image\": batch[1][i].item(), \"scores\": prediction[i][1].item()}\n",
        "    df=df.append(row, ignore_index=True)\n",
        "  df = df.sort_values(\"scores\", ascending=False)\n",
        "  df = df.reset_index()\n",
        "  df = df[[\"id_image\", \"scores\"]]\n",
        "  position_true = df[df.id_image.isin([y_true])].index[0] + 1\n",
        "  return position_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K79E44QulThU"
      },
      "source": [
        "#function that calulates scores(probability of correct association (image-text))\n",
        "def positive_scores(model, iterator, criterion):\n",
        "  \n",
        "  model.eval() \n",
        "  with torch.no_grad():\n",
        "      bar = pyprind.ProgBar(len(iterator), bar_char='â–ˆ')\n",
        "      positions = []\n",
        "      for batch in tqdm(iterator):\n",
        "        prediction = model(multi_dict(batch[0], vocabolario1,work_on_images=False), multi_dict(batch[1], vocabolario2)[0], multi_dict(batch[1], vocabolario2)[1].squeeze(-1)) #id_caption e id_img\n",
        "        prediction = F.softmax(prediction, dim = -1)[0]\n",
        "        positions.append(ranking_tracker(prediction,batch))\n",
        "\n",
        " \n",
        "      \n",
        "  return positions "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxkP9WuolFye"
      },
      "source": [
        "positions_ys_true = positive_scores(model,dataloader,criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3-0uhTzCXrV"
      },
      "source": [
        "#define recall at k using positions\n",
        "def recall_at_k(positions, k):\n",
        "  count=0\n",
        "  for i in positions:\n",
        "    if i <=k:\n",
        "      count+=1\n",
        "  print(f\"Recall at {k} is {count/len(positions)}\")\n",
        "  return count/len(positions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-yFrilKLuIb"
      },
      "source": [
        "recall_at_k(positions_ys_true,125)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XohydOkkCVAx"
      },
      "source": [
        "#create dataframe to see results\n",
        "df_recall = pd.DataFrame(columns =[\"dataset\", \"recall_1\", \"recall_5\", \"recall_10\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGSrBBqACohz"
      },
      "source": [
        "df_recall=df_recall.append({\"dataset\":1,\"recall_1\":recall_at_k(positions_ys_true, 1),\"recall_5\":recall_at_k(positions_ys_true, 5),\"recall_10\":recall_at_k(positions_ys_true, 10)},ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
